{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 61542,
          "databundleVersionId": 6888007,
          "sourceType": "competition"
        },
        {
          "sourceId": 6890527,
          "sourceType": "datasetVersion",
          "datasetId": 3942644
        },
        {
          "sourceId": 6977472,
          "sourceType": "datasetVersion",
          "datasetId": 4005256
        },
        {
          "sourceId": 7082713,
          "sourceType": "datasetVersion",
          "datasetId": 4039374
        },
        {
          "sourceId": 5916,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4689
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Overview:**<br>\n",
        "In recent years, large language models (LLMs) have become increasingly sophisticated, capable of generating text that is difficult to distinguish from human-written text. In this competition, we hope to foster open research and transparency on AI detection techniques applicable in the real world.\n",
        "<br>\n",
        "This competition challenges participants to develop a machine learning model that can accurately detect whether an essay was written by a student or an LLM. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs."
      ],
      "metadata": {
        "id": "MRMz5m-a8fNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Im using kaggle environment for training and testing purposes.\n",
        "* So, i loaded the data according to it."
      ],
      "metadata": {
        "id": "7dHqt-Zm9ioL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:19.622670Z",
          "iopub.execute_input": "2024-01-15T16:19:19.623109Z",
          "iopub.status.idle": "2024-01-15T16:19:20.118942Z",
          "shell.execute_reply.started": "2024-01-15T16:19:19.623075Z",
          "shell.execute_reply": "2024-01-15T16:19:20.117581Z"
        },
        "trusted": true,
        "id": "dCq7X8_o8Dg4",
        "outputId": "7f0bfca5-cd0a-41c5-87ad-0383bd2d15aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v3.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v5.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v7.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v6.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v2.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v1.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v7_15_percent_corruption.csv\n/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v4.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_03.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_02.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\n/kaggle/input/daigt-proper-train-dataset/train_drcat_01.csv\n/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n/kaggle/input/distil_bert/keras/distil_bert_base_en_uncased/1/config.json\n/kaggle/input/distil_bert/keras/distil_bert_base_en_uncased/1/tokenizer.json\n/kaggle/input/distil_bert/keras/distil_bert_base_en_uncased/1/metadata.json\n/kaggle/input/distil_bert/keras/distil_bert_base_en_uncased/1/model.weights.h5\n/kaggle/input/distil_bert/keras/distil_bert_base_en_uncased/1/assets/tokenizer/vocabulary.txt\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Below are the datasets provided with competition.\n",
        "* we can see that train_essays is highly imbalanced and test_essays(test data) is hidden."
      ],
      "metadata": {
        "id": "Zlsh3EWj-QIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=\"/kaggle/input/llm-detect-ai-generated-text/\"\n",
        "sample_submission=pd.read_csv(data_path+'sample_submission.csv')\n",
        "train_prompts=pd.read_csv(data_path+'train_prompts.csv')\n",
        "test_essays =pd.read_csv(data_path+\"test_essays.csv\")\n",
        "train_essays = pd.read_csv(data_path+\"train_essays.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.122220Z",
          "iopub.execute_input": "2024-01-15T16:19:20.123357Z",
          "iopub.status.idle": "2024-01-15T16:19:20.252085Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.123297Z",
          "shell.execute_reply": "2024-01-15T16:19:20.250958Z"
        },
        "trusted": true,
        "id": "0LC103BM8Dg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_submission.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.253384Z",
          "iopub.execute_input": "2024-01-15T16:19:20.253741Z",
          "iopub.status.idle": "2024-01-15T16:19:20.291898Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.253710Z",
          "shell.execute_reply": "2024-01-15T16:19:20.290700Z"
        },
        "trusted": true,
        "id": "3e4nLRgy8Dg-",
        "outputId": "238377ab-df11-45a0-9bdf-83137e1391f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   id         3 non-null      object \n 1   generated  3 non-null      float64\ndtypes: float64(1), object(1)\nmemory usage: 176.0+ bytes\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_prompts.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.293528Z",
          "iopub.execute_input": "2024-01-15T16:19:20.293856Z",
          "iopub.status.idle": "2024-01-15T16:19:20.305077Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.293827Z",
          "shell.execute_reply": "2024-01-15T16:19:20.304122Z"
        },
        "trusted": true,
        "id": "TkdDyvjS8Dg_",
        "outputId": "e9cc50e7-8193-48b1-f05b-69033758246a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2 entries, 0 to 1\nData columns (total 4 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   prompt_id     2 non-null      int64 \n 1   prompt_name   2 non-null      object\n 2   instructions  2 non-null      object\n 3   source_text   2 non-null      object\ndtypes: int64(1), object(3)\nmemory usage: 192.0+ bytes\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_essays.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.307467Z",
          "iopub.execute_input": "2024-01-15T16:19:20.308169Z",
          "iopub.status.idle": "2024-01-15T16:19:20.324462Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.308134Z",
          "shell.execute_reply": "2024-01-15T16:19:20.323227Z"
        },
        "trusted": true,
        "id": "kroZGkAi8Dg_",
        "outputId": "4bbd9c79-0962-4954-bcad-c4883964ff35"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1378 entries, 0 to 1377\nData columns (total 4 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         1378 non-null   object\n 1   prompt_id  1378 non-null   int64 \n 2   text       1378 non-null   object\n 3   generated  1378 non-null   int64 \ndtypes: int64(2), object(2)\nmemory usage: 43.2+ KB\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_essays.info())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.325883Z",
          "iopub.execute_input": "2024-01-15T16:19:20.326243Z",
          "iopub.status.idle": "2024-01-15T16:19:20.340086Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.326212Z",
          "shell.execute_reply": "2024-01-15T16:19:20.338801Z"
        },
        "trusted": true,
        "id": "YrZLbW7B8Dg_",
        "outputId": "b1ef5fb4-6c97-4226-b5c8-dacbcd2b02de"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3 entries, 0 to 2\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         3 non-null      object\n 1   prompt_id  3 non-null      int64 \n 2   text       3 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 200.0+ bytes\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays[\"generated\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.342028Z",
          "iopub.execute_input": "2024-01-15T16:19:20.342602Z",
          "iopub.status.idle": "2024-01-15T16:19:20.355392Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.342557Z",
          "shell.execute_reply": "2024-01-15T16:19:20.354484Z"
        },
        "trusted": true,
        "id": "BOyzP1488DhA",
        "outputId": "234252b4-0c4a-46ac-b67c-f0c5d043ac7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "generated\n0    1375\n1       3\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays[\"prompt_id\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.357081Z",
          "iopub.execute_input": "2024-01-15T16:19:20.357756Z",
          "iopub.status.idle": "2024-01-15T16:19:20.367277Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.357723Z",
          "shell.execute_reply": "2024-01-15T16:19:20.366270Z"
        },
        "trusted": true,
        "id": "SySPCGJd8DhA",
        "outputId": "d7560ea4-2895-47af-b4cf-9f92c683be9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "prompt_id\n0    708\n1    670\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Due to imbalance we need t find new data for the task\n",
        "* So, im adding a dataset consists of 4.9k AI written text essays into train_essays."
      ],
      "metadata": {
        "id": "WnhAkvmD-6CO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oth_dp=\"/kaggle/input/llm-mistral-7b-instruct-texts/Mistral7B_CME_v7.csv\"\n",
        "dataset1=pd.read_csv(oth_dp)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.368928Z",
          "iopub.execute_input": "2024-01-15T16:19:20.369622Z",
          "iopub.status.idle": "2024-01-15T16:19:20.698846Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.369589Z",
          "shell.execute_reply": "2024-01-15T16:19:20.697674Z"
        },
        "trusted": true,
        "id": "FX54VQUt8DhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.700157Z",
          "iopub.execute_input": "2024-01-15T16:19:20.700509Z",
          "iopub.status.idle": "2024-01-15T16:19:20.719318Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.700480Z",
          "shell.execute_reply": "2024-01-15T16:19:20.718160Z"
        },
        "trusted": true,
        "id": "dJCReJro8DhC",
        "outputId": "54b9faa2-aa7d-4bb1-bb14-4762c3ef3e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4900 entries, 0 to 4899\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   prompt_id    4900 non-null   int64 \n 1   text         4900 non-null   object\n 2   prompt_name  4900 non-null   object\n 3   generated    4900 non-null   int64 \ndtypes: int64(2), object(2)\nmemory usage: 153.2+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_delete = ['prompt_id','id']\n",
        "train_essays.drop(columns=columns_to_delete, inplace=True)\n",
        "columns_to_delete = ['prompt_id','prompt_name']\n",
        "dataset1.drop(columns=columns_to_delete, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.720911Z",
          "iopub.execute_input": "2024-01-15T16:19:20.721401Z",
          "iopub.status.idle": "2024-01-15T16:19:20.736659Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.721356Z",
          "shell.execute_reply": "2024-01-15T16:19:20.735501Z"
        },
        "trusted": true,
        "id": "T6UmNxHB8DhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays=pd.concat([train_essays,dataset1],ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.738749Z",
          "iopub.execute_input": "2024-01-15T16:19:20.739601Z",
          "iopub.status.idle": "2024-01-15T16:19:20.749252Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.739555Z",
          "shell.execute_reply": "2024-01-15T16:19:20.747519Z"
        },
        "trusted": true,
        "id": "0g-xmaj-8DhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.751098Z",
          "iopub.execute_input": "2024-01-15T16:19:20.751561Z",
          "iopub.status.idle": "2024-01-15T16:19:20.767553Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.751523Z",
          "shell.execute_reply": "2024-01-15T16:19:20.766324Z"
        },
        "trusted": true,
        "id": "Ite5z5xn8DhD",
        "outputId": "e15be790-8dd9-4811-9ebb-5ca3aac8f521"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6278 entries, 0 to 6277\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   text       6278 non-null   object\n 1   generated  6278 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 98.2+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays[\"generated\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.773787Z",
          "iopub.execute_input": "2024-01-15T16:19:20.774302Z",
          "iopub.status.idle": "2024-01-15T16:19:20.784002Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.774266Z",
          "shell.execute_reply": "2024-01-15T16:19:20.782737Z"
        },
        "trusted": true,
        "id": "WwjDwdO48DhD",
        "outputId": "89bd3f86-ad35-47ce-a0a3-7feaa63ecfbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "generated\n1    4903\n0    1375\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Still the data is less to be sent into a training model for classification.\n",
        "* So i added an another dataset with some applied filters.(with filters i got considerably higher public score than without.)"
      ],
      "metadata": {
        "id": "gzPwzJKU_SV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oth_dp=\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\"\n",
        "dataset2=pd.read_csv(oth_dp)\n",
        "dataset2.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:20.785633Z",
          "iopub.execute_input": "2024-01-15T16:19:20.786151Z",
          "iopub.status.idle": "2024-01-15T16:19:23.263369Z",
          "shell.execute_reply.started": "2024-01-15T16:19:20.786074Z",
          "shell.execute_reply": "2024-01-15T16:19:23.262165Z"
        },
        "trusted": true,
        "id": "IYg3A0958DhD",
        "outputId": "d076182a-ee33-4938-c36a-92fd7a6c51f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 44868 entries, 0 to 44867\nData columns (total 5 columns):\n #   Column         Non-Null Count  Dtype \n---  ------         --------------  ----- \n 0   text           44868 non-null  object\n 1   label          44868 non-null  int64 \n 2   prompt_name    44868 non-null  object\n 3   source         44868 non-null  object\n 4   RDizzl3_seven  44868 non-null  bool  \ndtypes: bool(1), int64(1), object(3)\nmemory usage: 1.4+ MB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset2 = dataset2[dataset2.RDizzl3_seven]\n",
        "columns_to_delete = ['prompt_name','source','RDizzl3_seven']\n",
        "dataset2.drop(columns=columns_to_delete, inplace=True)\n",
        "dataset2=dataset2.rename(columns={\n",
        "    \"text\":\"text\",\n",
        "    \"label\":\"generated\"\n",
        "})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:23.265026Z",
          "iopub.execute_input": "2024-01-15T16:19:23.265396Z",
          "iopub.status.idle": "2024-01-15T16:19:23.287678Z",
          "shell.execute_reply.started": "2024-01-15T16:19:23.265363Z",
          "shell.execute_reply": "2024-01-15T16:19:23.286522Z"
        },
        "trusted": true,
        "id": "QCaUduM18DhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays=pd.concat([train_essays,dataset2],ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:23.289171Z",
          "iopub.execute_input": "2024-01-15T16:19:23.290074Z",
          "iopub.status.idle": "2024-01-15T16:19:23.296809Z",
          "shell.execute_reply.started": "2024-01-15T16:19:23.290037Z",
          "shell.execute_reply": "2024-01-15T16:19:23.295845Z"
        },
        "trusted": true,
        "id": "shAxU1kw8DhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I tried adding more data for training but it does'nt helped to increase score."
      ],
      "metadata": {
        "id": "vZUOjHc4AaD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# oth_dp=\"/kaggle/input/daigt-proper-train-dataset/train_drcat_04.csv\"\n",
        "# dataset3=pd.read_csv(oth_dp)\n",
        "# dataset3.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:23.297908Z",
          "iopub.execute_input": "2024-01-15T16:19:23.298850Z",
          "iopub.status.idle": "2024-01-15T16:19:26.071340Z",
          "shell.execute_reply.started": "2024-01-15T16:19:23.298816Z",
          "shell.execute_reply": "2024-01-15T16:19:26.070140Z"
        },
        "trusted": true,
        "id": "RbV1PgHI8DhE",
        "outputId": "d332c6a6-8c45-46a3-d6ed-3551a8a8dadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 44206 entries, 0 to 44205\nData columns (total 6 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   essay_id  44206 non-null  object\n 1   text      44206 non-null  object\n 2   label     44206 non-null  int64 \n 3   source    44206 non-null  object\n 4   prompt    12911 non-null  object\n 5   fold      44206 non-null  int64 \ndtypes: int64(2), object(4)\nmemory usage: 2.0+ MB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# columns_to_delete = ['essay_id','source','prompt','fold']\n",
        "# dataset3.drop(columns=columns_to_delete, inplace=True)\n",
        "# dataset3=dataset3.rename(columns={\n",
        "#     \"text\":\"text\",\n",
        "#     \"label\":\"generated\"\n",
        "# })\n",
        "# dataset3.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.073730Z",
          "iopub.execute_input": "2024-01-15T16:19:26.074072Z",
          "iopub.status.idle": "2024-01-15T16:19:26.111967Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.074043Z",
          "shell.execute_reply": "2024-01-15T16:19:26.110653Z"
        },
        "trusted": true,
        "id": "sGhXjjUR8DhE",
        "outputId": "16964d76-6658-4259-816c-1ecf4464169d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 44206 entries, 0 to 44205\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   text       44206 non-null  object\n 1   generated  44206 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 690.8+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_essays=pd.concat([train_essays,dataset3],ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.113345Z",
          "iopub.execute_input": "2024-01-15T16:19:26.113778Z",
          "iopub.status.idle": "2024-01-15T16:19:26.122385Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.113741Z",
          "shell.execute_reply": "2024-01-15T16:19:26.120916Z"
        },
        "trusted": true,
        "id": "DbmqMGO_8DhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays=train_essays.sample(frac=1, random_state=56)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.124076Z",
          "iopub.execute_input": "2024-01-15T16:19:26.124946Z",
          "iopub.status.idle": "2024-01-15T16:19:26.139520Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.124900Z",
          "shell.execute_reply": "2024-01-15T16:19:26.138003Z"
        },
        "trusted": true,
        "id": "tzgzhTAh8DhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* At the end, I left with the dataset consists of around 26.7k entries with 58% of human written essays and rest are Ai generated essays."
      ],
      "metadata": {
        "id": "DAg7Ggc8AwTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.141119Z",
          "iopub.execute_input": "2024-01-15T16:19:26.141577Z",
          "iopub.status.idle": "2024-01-15T16:19:26.163822Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.141526Z",
          "shell.execute_reply": "2024-01-15T16:19:26.162480Z"
        },
        "trusted": true,
        "id": "pqwqLRVE8DhF",
        "outputId": "7d8cf824-edd1-4664-81a4-8d7dde0ec90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nIndex: 26728 entries, 21480 to 2532\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   text       26728 non-null  object\n 1   generated  26728 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 626.4+ KB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_essays[\"generated\"].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.165693Z",
          "iopub.execute_input": "2024-01-15T16:19:26.166163Z",
          "iopub.status.idle": "2024-01-15T16:19:26.178173Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.166117Z",
          "shell.execute_reply": "2024-01-15T16:19:26.176889Z"
        },
        "trusted": true,
        "id": "HMO1wpxi8DhF",
        "outputId": "8ddd8cb6-a10e-4c96-c077-fccebf1b7883"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "generated\n0    15625\n1    11103\nName: count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data-Preprocessing**<br>\n",
        "* For improving model performance, i did some changes to data By.\n",
        "\n",
        "\n",
        "1.   Changing it into lower-case so, model doesnt discriminate between the same word which is written another case.\n",
        "2.   Removing puncutations and special characters.\n",
        "3. Removing stopwords( stopwords are the words which doesnt contribute to sentence meaning but used quiet often.)\n",
        "4. Removing neumerical characters.\n",
        "5. And at last trasforming text into tokens(tokenize).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6XW418bUBQEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def transform_text(df,column):\n",
        "    df[column]=df[column].str.lower()\n",
        "    df[column] = df[column].apply(remove_punctuation)\n",
        "    df[column] = df[column].apply(remove_stopwords)\n",
        "    df[column] = df[column].str.replace('\\d+', '')\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(df[column])\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:26.179730Z",
          "iopub.execute_input": "2024-01-15T16:19:26.180919Z",
          "iopub.status.idle": "2024-01-15T16:19:41.137545Z",
          "shell.execute_reply.started": "2024-01-15T16:19:26.180881Z",
          "shell.execute_reply": "2024-01-15T16:19:41.136513Z"
        },
        "trusted": true,
        "id": "FwEiwadh8DhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* After pre-processing, The processed data is passed into a vectorizer, here im using tf-idf vectorizer from sklearn."
      ],
      "metadata": {
        "id": "1FZ4msmCDYNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_essays=transform_text(train_essays,'text')\n",
        "\n",
        "x=train_essays.text\n",
        "y=train_essays.generated\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x)\n",
        "\n",
        "x = vectorizer.transform(x)\n",
        "test_essays=transform_text(test_essays,'text')\n",
        "\n",
        "test_text=test_essays.text\n",
        "test_transform = vectorizer.transform(test_text)\n",
        "test_transform[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:19:41.139044Z",
          "iopub.execute_input": "2024-01-15T16:19:41.140024Z",
          "iopub.status.idle": "2024-01-15T16:20:42.910385Z",
          "shell.execute_reply.started": "2024-01-15T16:19:41.139984Z",
          "shell.execute_reply": "2024-01-15T16:20:42.909170Z"
        },
        "trusted": true,
        "id": "d_ajL_IS8DhF",
        "outputId": "ef3a6405-7347-467e-c8df-2fcff159c018"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<1x75567 sparse matrix of type '<class 'numpy.float64'>'\n\twith 1 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The output of tf-idf vectorizer is a sparse matrix consists of floating point numbers."
      ],
      "metadata": {
        "id": "H2fdY9eFD20E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model implementation**"
      ],
      "metadata": {
        "id": "9hG4R-5oEZEt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**<br>\n",
        "&emsp; Before mid-eval i have implemented few models(namely : sgd classifier, logistic reggresion, and Multinomail Naive Bayes).\n",
        "* By using the above models i got maximum score of 0.81.\n",
        "* So i tried ensembling them, resulting a score increase to 0.857.\n",
        "* i tried various combinations and changing the model parameters, for below one i got maximum score of 0.885."
      ],
      "metadata": {
        "id": "YCAZHGh3EhQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "# Training classifier model\n",
        "# Logistic Regression model\n",
        "# lr = LogisticRegression(verbose=1)\n",
        "\n",
        "# Multinomial Naive Bayes model\n",
        "clf = MultinomialNB(alpha=0.0225)\n",
        "\n",
        "# SGDClassifier models with different hyperparameters\n",
        "sgd_model = SGDClassifier(max_iter=8000, tol=1e-3, loss=\"modified_huber\")\n",
        "sgd_model2 = SGDClassifier(max_iter=12000, tol=5e-4, loss=\"modified_huber\", class_weight=\"balanced\")\n",
        "# sgd_model3 = SGDClassifier(max_iter=15000, tol=3e-4, loss=\"modified_huber\", early_stopping=True)\n",
        "\n",
        "# Ensemble VotingClassifier\n",
        "final_model = VotingClassifier(\n",
        "    estimators=[('sgd', sgd_model),('sgd_2', sgd_model2),('mnb', clf)],\n",
        "    weights=[0.10,0.54,0.36],\n",
        "    voting='soft',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "final_model.fit(x,y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:22:22.318808Z",
          "iopub.execute_input": "2024-01-15T16:22:22.319289Z",
          "iopub.status.idle": "2024-01-15T16:22:22.895505Z",
          "shell.execute_reply.started": "2024-01-15T16:22:22.319254Z",
          "shell.execute_reply": "2024-01-15T16:22:22.893122Z"
        },
        "trusted": true,
        "id": "8cvEx2fy8DhG",
        "outputId": "0a1403c3-8a09-43b5-c19b-b851fab31fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[Voting] ...................... (1 of 3) Processing sgd, total=   0.2s\n[Voting] .................... (2 of 3) Processing sgd_2, total=   0.3s\n[Voting] ...................... (3 of 3) Processing mnb, total=   0.0s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "VotingClassifier(estimators=[('sgd',\n                              SGDClassifier(loss='modified_huber',\n                                            max_iter=8000)),\n                             ('sgd_2',\n                              SGDClassifier(class_weight='balanced',\n                                            loss='modified_huber',\n                                            max_iter=12000, tol=0.0005)),\n                             ('mnb', MultinomialNB(alpha=0.0225))],\n                 verbose=1, voting='soft', weights=[0.1, 0.54, 0.36])",
            "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;sgd&#x27;,\n                              SGDClassifier(loss=&#x27;modified_huber&#x27;,\n                                            max_iter=8000)),\n                             (&#x27;sgd_2&#x27;,\n                              SGDClassifier(class_weight=&#x27;balanced&#x27;,\n                                            loss=&#x27;modified_huber&#x27;,\n                                            max_iter=12000, tol=0.0005)),\n                             (&#x27;mnb&#x27;, MultinomialNB(alpha=0.0225))],\n                 verbose=1, voting=&#x27;soft&#x27;, weights=[0.1, 0.54, 0.36])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;sgd&#x27;,\n                              SGDClassifier(loss=&#x27;modified_huber&#x27;,\n                                            max_iter=8000)),\n                             (&#x27;sgd_2&#x27;,\n                              SGDClassifier(class_weight=&#x27;balanced&#x27;,\n                                            loss=&#x27;modified_huber&#x27;,\n                                            max_iter=12000, tol=0.0005)),\n                             (&#x27;mnb&#x27;, MultinomialNB(alpha=0.0225))],\n                 verbose=1, voting=&#x27;soft&#x27;, weights=[0.1, 0.54, 0.36])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sgd</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;modified_huber&#x27;, max_iter=8000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sgd_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(class_weight=&#x27;balanced&#x27;, loss=&#x27;modified_huber&#x27;, max_iter=12000,\n              tol=0.0005)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mnb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.0225)</pre></div></div></div></div></div></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "oKpnthQDGm0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_probs = final_model.predict_proba(test_transform)\n",
        "y_probs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:22:22.898114Z",
          "iopub.execute_input": "2024-01-15T16:22:22.899039Z",
          "iopub.status.idle": "2024-01-15T16:22:22.909120Z",
          "shell.execute_reply.started": "2024-01-15T16:22:22.898992Z",
          "shell.execute_reply": "2024-01-15T16:22:22.908121Z"
        },
        "trusted": true,
        "id": "ek2O627q8DhG",
        "outputId": "7d274479-8f00-45ac-fbee-3629b7187757"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.30359801, 0.69640199],\n       [0.51892787, 0.48107213],\n       [0.51892787, 0.48107213]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_gen_prob =[y[1] for y in y_probs]\n",
        "y_gen_prob"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:22:22.910920Z",
          "iopub.execute_input": "2024-01-15T16:22:22.911899Z",
          "iopub.status.idle": "2024-01-15T16:22:22.921399Z",
          "shell.execute_reply.started": "2024-01-15T16:22:22.911853Z",
          "shell.execute_reply": "2024-01-15T16:22:22.920127Z"
        },
        "trusted": true,
        "id": "8AeIkvTK8DhG",
        "outputId": "2bab1c30-fea6-4dec-bd4f-abcec929a76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0.6964019911057642, 0.48107213192821385, 0.48107213192821385]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = test_essays[[\"id\"]].copy()\n",
        "\n",
        "sub[\"generated\"] = y_gen_prob\n",
        "\n",
        "# Save Submission\n",
        "sub.to_csv('submission.csv',index=False)\n",
        "\n",
        "sub.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-15T16:22:22.923357Z",
          "iopub.execute_input": "2024-01-15T16:22:22.923861Z",
          "iopub.status.idle": "2024-01-15T16:22:22.947056Z",
          "shell.execute_reply.started": "2024-01-15T16:22:22.923814Z",
          "shell.execute_reply": "2024-01-15T16:22:22.946213Z"
        },
        "trusted": true,
        "id": "fgv9tVmH8DhG",
        "outputId": "1042aacc-db2a-46ba-9a76-18268fce64fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         id  generated\n0  0000aaaa   0.696402\n1  1111bbbb   0.481072\n2  2222cccc   0.481072",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>0.696402</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1111bbbb</td>\n      <td>0.481072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222cccc</td>\n      <td>0.481072</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final score for the above model i got **0.885** score in kaggle. <br>*username : uranaveer*"
      ],
      "metadata": {
        "id": "4CpmFHl3MBkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In addition to above i have also tried, other models like bert. but i didnt got better score. for parameters tuning and training it consumed lot of time and computaional resources. so i didnt proceed with that."
      ],
      "metadata": {
        "id": "Fx998eJjHb8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import keras_nlp\n",
        "# import keras\n",
        "# from keras import layers\n",
        "\n",
        "# preprocessor1 = keras_nlp.models.DistilBertPreprocessor.from_preset(\n",
        "#     \"distil_bert_base_en_uncased\",\n",
        "#     sequence_length=512,\n",
        "# )\n",
        "# x = preprocessor1(x)\n",
        "# x_val = preprocessor1(x_val)\n",
        "# classifier = keras_nlp.models.DistilBertClassifier.from_preset(\n",
        "#     \"distil_bert_base_en_uncased\",\n",
        "#     num_classes=1,\n",
        "# )\n",
        "# classifier.backbone.trainable = False\n",
        "\n",
        "# classifier.compile(\n",
        "#     loss=['binary_crossentropy'],\n",
        "#     optimizer=keras.optimizers.Adam(1e-4),\n",
        "#     jit_compile=True,\n",
        "#     metrics = ['accuracy','AUC']\n",
        "# )\n",
        "\n",
        "\n",
        "# classifier.fit(x= x, y=y, batch_size=8 ,epochs =5,\n",
        "#                validation_data = (x_val,y_val))"
      ],
      "metadata": {
        "id": "wCUWSws-Lvit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}